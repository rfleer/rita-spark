{"cells":[{"cell_type":"markdown","source":["# FAQ"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"24f23e59-338d-41b5-a130-574524414850","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### 1. Why the notebook does not run though I have created a cluster?"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e7423261-ea75-4591-ba3f-8ba9099e2676","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["It might happen because of incorrect attachement of cluster. In such cases you're better to:\n - Detach the cluster (choose this option when clicking on it) and attach it again\n - Kill the cluster and just try to run the cell so that Databricks creates default cluster for you"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"82bb27ec-41c1-46a6-92a6-0bfff0473f62","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### 2. How do I know what files I currently have as available data on Databricks?"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"af8374c6-78e0-442c-a080-fe579a5ee390","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["You can access the data directory contents usually with `%fs ls /FileStore/tables/` (as Databricks supports basic Linux commands in file system mode), and then e.g. remove the files/folders that you do not need anymore by running `%fs rm -r /FileStore/tables/<FILENAME>`."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c784d84f-38fd-4396-9aea-1836350c440e","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### 3. Why do I have `Running command ...` in `netcat` and it does not finish?"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"48f3c1cf-024a-4b36-bc12-bfbb63afb364","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["If you have it in cell 4 - then you did everything correctly :) This is how the streaming technology works, and in our case we've provided the \"topic producer\" using `socket` Python package, which is streaming data via [TCP protocol](https://www.fortinet.com/resources/cyberglossary/tcp-ip) of data transmission. \n\nBelow are the good sources to learn more about Socket:\n\n - [Official Python documentation](https://docs.python.org/3/howto/sockets.html)\n - [Socket Programming in Python (Guide)](https://realpython.com/python-sockets/)\n - [Python Socket Programming Tutorial (YouTube video)](https://www.youtube.com/watch?v=3QiPPX-KeSc)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ebfe8c87-a039-4c40-ada9-6d756187a267","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### 4. I have stopped the streaming and tried to start it once again, however got an error:\n### `OSError: [Errno 98] Address already in use`"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"80e66bf6-04b2-4440-a3cd-199816398949","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Unfortunately, this is the case of running some job using the port. In our case we had a job on port 9999 - after starting the job in cell, we should also free the port by killing the process on it. However, even though Databricks supports basic Linux commands, this option is not available. So the easiest fix is to change the port from 9999 to e.g. 9998 - but in this case you might be out of free ports in some time, so you can simply restart a cluster."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"937d8ab7-90ae-48ac-bbde-15976356b832","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### 5. Why should I call `.foreachRDD(<some_function>)` in the end of function for processing stream? If I do not do it, nothing works"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f39c0c1b-da9d-4d22-8417-dd3bdfc535d2","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["This happens because of Apache Spark being lazy, and not making any calculations unless the materialized output is to be provided. So that in our example we implement the easiest thing and specify for each RDD the `.collect()` that retrieves all the elements."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e119ad56-9227-40ee-ac4a-b27af84015e6","inputWidgets":{},"title":""}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"21e87053-8c29-4bf7-a371-7941557a6930","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.8.3","nbconvert_exporter":"python","file_extension":".py"},"application/vnd.databricks.v1+notebook":{"notebookName":"FAQ_Lab1","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":568697239625237}},"nbformat":4,"nbformat_minor":0}
